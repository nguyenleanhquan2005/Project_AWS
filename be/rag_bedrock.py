import boto3
import json
import uuid
import math
import pypdf
import re

class BedrockRAG:
    def __init__(self):
        self.bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')
        self.chunk_size = 800
        self.chunk_overlap = 100
    
    def get_titan_embedding(self, text):
        """L·∫•y embedding t·ª´ Amazon Titan (FREE)"""
        try:
            # Clean text ƒë·ªÉ tr√°nh l·ªói
            clean_text = text.replace('\x00', '').strip()
            if not clean_text:
                return None
                
            body = json.dumps({
                "inputText": clean_text
            })
            
            response = self.bedrock_runtime.invoke_model(
                modelId='amazon.titan-embed-text-v1',
                body=body
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['embedding']
            
        except Exception as e:
            print(f"Embedding error: {e}")
            return None
    
    def invoke_claude(self, prompt, max_tokens=1000):
        """G·ªçi Claude cho generation"""
        try:
            body = json.dumps({
                "prompt": f"\n\nHuman: {prompt}\n\nAssistant:",
                "max_tokens_to_sample": max_tokens,
                "temperature": 0.7,
                "top_p": 0.9,
            })
            
            response = self.bedrock_runtime.invoke_model(
                modelId='anthropic.claude-instant-v1',
                body=body
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['completion']
            
        except Exception as e:
            print(f"Claude error: {e}")
            return None
    
    def invoke_titan(self, prompt, max_tokens=1000):
        """G·ªçi Amazon Titan cho generation (FREE)"""
        try:
            body = json.dumps({
                "inputText": prompt,
                "textGenerationConfig": {
                    "maxTokenCount": max_tokens,
                    "temperature": 0.7,
                    "topP": 0.9,
                }
            })
            
            response = self.bedrock_runtime.invoke_model(
                modelId='amazon.titan-text-lite-v1',
                body=body
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['results'][0]['outputText']
            
        except Exception as e:
            print(f"Titan error: {e}")
            return None
    
    def load_and_split_document(self, file_path):
        """Load v√† chia nh·ªè document"""
        print(f"üìñ Loading document: {file_path}")
        
        try:
            if file_path.lower().endswith('.pdf'):
                text = self._extract_pdf_text(file_path)
            else:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
            
            chunks = self._split_text(text)
            print(f"üìÑ Split into {len(chunks)} chunks")
            return chunks
        except Exception as e:
            print(f"‚ùå Document loading error: {e}")
            return []
    
    def _extract_pdf_text(self, file_path):
        """Extract text from PDF"""
        text = ""
        with open(file_path, 'rb') as file:
            pdf_reader = pypdf.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        return text
    
    def _split_text(self, text):
        """Split text into chunks"""
        # Simple text splitting
        sentences = re.split(r'[.!?]+', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            if len(current_chunk) + len(sentence) < self.chunk_size:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append({"page_content": current_chunk.strip()})
                current_chunk = sentence + ". "
        
        if current_chunk:
            chunks.append({"page_content": current_chunk.strip()})
            
        return chunks
    
    def cosine_similarity(self, a, b):
        """T√≠nh cosine similarity gi·ªØa 2 vectors"""
        if not a or not b or len(a) != len(b):
            return -1
        
        try:
            dot = sum(x * y for x, y in zip(a, b))
            norm_a = math.sqrt(sum(x * x for x in a))
            norm_b = math.sqrt(sum(x * x for x in b))
            
            if norm_a == 0 or norm_b == 0:
                return -1
                
            return dot / (norm_a * norm_b)
        except Exception as e:
            print(f"Cosine similarity error: {e}")
            return -1
    
    def create_vector_store(self, chunks):
        """T·∫°o vector store v·ªõi Titan embeddings (kh√¥ng d√πng FAISS)"""
        print("üîÑ Creating vector store v·ªõi Titan embeddings...")
        
        texts = [chunk["page_content"] for chunk in chunks]
        embeddings = []
        
        for i, text in enumerate(texts):
            if i % 5 == 0:  # Log progress every 5 chunks
                print(f"üìä Processing chunk {i+1}/{len(texts)}")
            
            embedding = self.get_titan_embedding(text)
            if embedding:
                embeddings.append(embedding)
            else:
                # Fallback: zero vector v·ªõi k√≠ch th∆∞·ªõc m·∫∑c ƒë·ªãnh c·ªßa Titan
                embeddings.append([0.0] * 1536)
        
        return {
            'chunks': chunks,
            'texts': texts,
            'embeddings': embeddings
        }
    
    def similarity_search(self, vector_store, query, k=3):
        """T√¨m c√°c chunk li√™n quan nh·∫•t b·∫±ng cosine similarity"""
        # L·∫•y embedding cho query
        query_embedding = self.get_titan_embedding(query)
        if not query_embedding:
            print("‚ùå Failed to get query embedding, using fallback search")
            return self.fallback_search(vector_store, query, k)
        
        # T√≠nh similarity v·ªõi t·∫•t c·∫£ chunks
        similarities = []
        for i, emb in enumerate(vector_store['embeddings']):
            sim = self.cosine_similarity(query_embedding, emb)
            similarities.append((i, sim))
        
        # S·∫Øp x·∫øp theo similarity gi·∫£m d·∫ßn
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # L·∫•y top k chunks
        relevant_chunks = []
        for idx, score in similarities[:k]:
            if idx < len(vector_store['chunks']) and score > 0:  # Ch·ªâ l·∫•y chunks c√≥ similarity > 0
                relevant_chunks.append(vector_store['chunks'][idx])
        
        print(f"üîç Found {len(relevant_chunks)} relevant chunks (best similarity: {similarities[0][1] if similarities else 0:.3f})")
        return relevant_chunks
    
    def fallback_search(self, vector_store, query, k=3):
        """Fallback search khi kh√¥ng c√≥ embeddings"""
        print("üîÑ Using fallback keyword search")
        query_lower = query.lower()
        
        scores = []
        for i, text in enumerate(vector_store['texts']):
            score = text.lower().count(query_lower)
            scores.append((i, score))
        
        scores.sort(key=lambda x: x[1], reverse=True)
        
        relevant_chunks = []
        for idx, score in scores[:k]:
            if score > 0:  # Ch·ªâ l·∫•y chunks c√≥ keyword match
                relevant_chunks.append(vector_store['chunks'][idx])
        
        return relevant_chunks
    
    def answer_question(self, vector_store, question):
        """Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n RAG"""
        print(f"üîç Searching for relevant content for: {question}")
        
        # T√¨m c√°c chunk li√™n quan
        relevant_chunks = self.similarity_search(vector_store, question, k=3)
        
        if not relevant_chunks:
            return "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu. Vui l√≤ng th·ª≠ c√¢u h·ªèi kh√°c ho·∫∑c t·∫£i l√™n t√†i li·ªáu ph√π h·ª£p h∆°n."
        
        # X√¢y d·ª±ng context
        context = "\n\n".join([
            f"ƒêo·∫°n {i+1}: {chunk['page_content']}" 
            for i, chunk in enumerate(relevant_chunks)
        ])
        
        # T·∫°o prompt cho RAG
        prompt = f"""
        H√£y ƒë·ªçc k·ªπ c√°c ƒëo·∫°n vƒÉn b·∫£n sau t·ª´ t√†i li·ªáu:

        {context}

        D·ª±a TR√äN c√°c ƒëo·∫°n vƒÉn b·∫£n tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi sau:
        C√¢u h·ªèi: {question}

        Y√äU C·∫¶U QUAN TR·ªåNG:
        - CH·ªà s·ª≠ d·ª•ng th√¥ng tin t·ª´ c√°c ƒëo·∫°n vƒÉn b·∫£n tr√™n
        - KH√îNG s·ª≠ d·ª•ng ki·∫øn th·ª©c b√™n ngo√†i
        - N·∫øu kh√¥ng ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi, h√£y n√≥i r√µ: "Kh√¥ng c√≥ ƒë·ªß th√¥ng tin trong t√†i li·ªáu ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y"
        - Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng v√† chi ti·∫øt
        - Gi·ªØ nguy√™n t√™n ri√™ng, thu·∫≠t ng·ªØ chuy√™n m√¥n t·ª´ t√†i li·ªáu g·ªëc

        Tr·∫£ l·ªùi:
        """
        
        print("ü§ñ Generating answer with Bedrock...")
        
        # ∆Øu ti√™n d√πng Titan (free), fallback Claude
        answer = self.invoke_titan(prompt)
        if not answer:
            answer = self.invoke_claude(prompt)
        
        if not answer:
            return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi ngay l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau."
        
        # Clean answer
        answer = answer.strip()
        if answer.startswith('"') and answer.endswith('"'):
            answer = answer[1:-1]
            
        return answer

# Global instance
bedrock_rag = BedrockRAG()

# Test function ƒë·ªÉ debug local
if __name__ == "__main__":
    # Test embedding
    rag = BedrockRAG()
    test_text = "Xin ch√†o, ƒë√¢y l√† test"
    embedding = rag.get_titan_embedding(test_text)
    print(f"Embedding test: {len(embedding) if embedding else 'FAILED'}")
    
    # Test generation
    response = rag.invoke_titan("Gi·ªõi thi·ªáu ng·∫Øn v·ªÅ AWS")
    print(f"Generation test: {response[:100] if response else 'FAILED'}")